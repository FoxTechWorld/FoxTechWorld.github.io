<!doctype html><html lang=pt-BR><head><title>Osdev: O multithread perdido - Pervasive Multithread // FoxTechWorld</title><link rel="shortcut icon" href=images/favicon.png><link rel=apple-touch-icon sizes=180x180 href=https://foxtechword.github.io/images/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=https://foxtechword.github.io/images/favicon-32.png><link rel=icon type=image/png sizes=16x16 href=https://foxtechword.github.io/images/favicon-16.png><link rel=icon type=image/png sizes=48x48 href=https://foxtechword.github.io/images/favicon-48.png><link rel=icon type=image/png sizes=192x192 href=https://foxtechword.github.io/images/android-chrome-192x192.png><link rel=icon type=image/png sizes=512x512 href=https://foxtechword.github.io/images/android-chrome-512x512.png><meta charset=utf-8><meta name=generator content="Hugo 0.156.0-DEV"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=author content="KitsuneSemCalda"><meta name=description content><link rel=stylesheet href=https://foxtechword.github.io/css/main.min.89e5f67d115df5e3aa766f49679ae017557cc19a8d2a174f4f5760f05edf0229.css><script async src="https://www.googletagmanager.com/gtag/js?id=G-5Z4YGJXDLT"></script><script>var doNotTrack=!1,dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes";if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-5Z4YGJXDLT")}</script><meta name=twitter:card content="summary"><meta name=twitter:title content="Osdev: O multithread perdido - Pervasive Multithread"><meta name=twitter:description content="Quando olhamos a história dos sistemas operacionais vemos muitas ideias promissoras nascerem, ganharem nichos e, às vezes, sumirem sem deixar rastro. Entre esses projetos, o BeOS — e seu sucessor Haiku — se destacam por uma opção arquitetural clara: priorizar interatividade e baixa latência por meio do que se chamou de Pervasive Multithread.
O diferencial do BeOS / Haiku O ponto central é simples: escalonar no nível da thread, com threads muito leves e políticas que favorecem responsividade em vez de throughput máximo. Isso reduz a sobrecarga de contexto ao trocar entre threads da mesma aplicação e permite uma taxa alta de comutação sem penalizar a interatividade."><meta property="og:url" content="https://foxtechword.github.io/2025/11/28/osdev-o-multithread-perdido-pervasive-multithread/"><meta property="og:site_name" content="FoxTechWorld"><meta property="og:title" content="Osdev: O multithread perdido - Pervasive Multithread"><meta property="og:description" content="Quando olhamos a história dos sistemas operacionais vemos muitas ideias promissoras nascerem, ganharem nichos e, às vezes, sumirem sem deixar rastro. Entre esses projetos, o BeOS — e seu sucessor Haiku — se destacam por uma opção arquitetural clara: priorizar interatividade e baixa latência por meio do que se chamou de Pervasive Multithread.
O diferencial do BeOS / Haiku O ponto central é simples: escalonar no nível da thread, com threads muito leves e políticas que favorecem responsividade em vez de throughput máximo. Isso reduz a sobrecarga de contexto ao trocar entre threads da mesma aplicação e permite uma taxa alta de comutação sem penalizar a interatividade."><meta property="og:locale" content="pt_BR"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-11-28T12:31:28-03:00"><meta property="article:modified_time" content="2025-11-28T12:31:28-03:00"><meta property="article:tag" content="Programming"><meta property="article:tag" content="Operating System"><meta property="article:tag" content="Osdev"><meta property="article:tag" content="C++"><meta property="article:tag" content="Haiku"><meta property="article:tag" content="Beos"><meta name=google-site-verification content="XXEJNvdhFFbUcmcEG1i9z2AaaEEKwZqE_qsFGO3ymWw"></head><body><header class=app-header><a href=https://foxtechword.github.io/><img class=app-header-avatar src=https://foxtechword.github.io/images/avatar.png alt=KitsuneSemCalda></a>
<span class=app-header-title>FoxTechWorld</span><nav class=app-header-menu><a class=app-header-menu-item href=https://foxtechword.github.io/>Home</a>
-
<a class=app-header-menu-item href=https://foxtechword.github.io/posts/>Posts</a>
-
<a class=app-header-menu-item href=https://foxtechword.github.io/tags/>Tags</a>
-
<a class=app-header-menu-item href=https://foxtechword.github.io/rss.xml>Rss</a></nav><p>Tentando tornar o mundo menos pop e mais nérdico</p><div class=app-header-social><a href=https://github.com/KitsuneSemCalda target=_blank rel="noreferrer noopener me"><svg class="icon icon-brand-github" viewBox="0 0 24 24" fill="currentColor"><title>GitHub</title><path d="M12 .3C5.4.3.0 5.7.0 12 0 18 3.4 22 8.2 24 8.8 24 9 23 9 23 9 23 9 22 9 21 5.7 22 5 19 5 19 4.4 18 3.6 18 3.6 18 2.5 17 3.7 17 3.7 17 4.9 17 5.6 18 5.6 18 6.6 20 8.4 20 9.1 19 9.2 18 9.5 18 9.8 18 7.1 17 4.3 16 4.3 12c0-1.3.47-2.4 1.2-3.2-.14-.3-.54-1.5.11-3.2.0.0 1-.32 3.3 1.2.96-.27 2-.4 3-.41 1 .006 2 .14 3 .41C17 5 18 5.3 18 5.3 19 6.9 19 8.1 18 8.5 19 9.3 20 10 20 12 20 16 17 17 14 18 15 18 15 19 15 20 15 21 15 23 15 23c0 .32.21.69.83.57C21 22 24 18 24 12c0-6.6-5.4-12-12-12"/></svg>
</a><a href=https://twitter.com/@KitsuneSemCalda target=_blank rel="noreferrer noopener me"><svg class="icon icon-brand-x" viewBox="0 0 24 24" fill="currentColor"><title>X</title><path d="M19 1.2H23L15 10 24 23H17L11 15 4.2 23H.47L9.1 13 0 1.2h7.6L13 8.1zM18 21h2l-13-17H4.3z"/></svg>
</a><a href=https://discord.gg/WTMr49Nfp5 target=_blank rel="noreferrer noopener me"><svg class="icon icon-brand-discord" viewBox="0 0 24 24" fill="currentColor"><title>Discord</title><path d="M20 4.4A20 20 0 0015 2.9.074.074.0 0015 2.9C15 3.3 15 3.8 15 4.1 13 3.9 11 3.9 9.3 4.1 9.1 3.7 8.9 3.3 8.6 2.9A.077.077.0 008.6 2.9 20 20 0 003.7 4.4.07.07.0 003.6 4.4C.53 9-.32 14 .099 18A.082.082.0 00.13 18c2.1 1.5 4 2.4 6 3A.078.078.0 006.2 21c.46-.63.87-1.3 1.2-2A.076.076.0 007.4 19C6.7 19 6.1 18 5.5 18A.077.077.0 015.5 18C5.6 18 5.8 18 5.9 18A.074.074.0 016 18C9.9 19 14 19 18 18A.074.074.0 0118 18C18 18 18 18 18 18A.077.077.0 0118 18 12 12 0 0117 19 .077.077.0 0017 19C17 20 17 20 18 21A.076.076.0 0018 21c2-.61 3.9-1.5 6-3A.077.077.0 0024 18C24 13 23 8.4 20 4.4A.061.061.0 0020 4.4zM8 15C6.8 15 5.9 14 5.9 13 5.9 12 6.8 10 8 10 9.2 10 10 12 10 13 10 14 9.2 15 8 15zm8 0C15 15 14 14 14 13 14 12 15 10 16 10 17 10 18 12 18 13 18 14 17 15 16 15z"/></svg>
</a><a href=https://youtube.com/@FoxTechWorld target=_blank rel="noreferrer noopener me"><svg class="icon icon-brand-youtube" viewBox="0 0 24 24" fill="currentColor"><title>YouTube</title><path d="M23 6.2A3 3 0 0021 4.1C20 3.5 12 3.5 12 3.5s-7.5.0-9.4.51A3 3 0 00.5 6.2C0 8.1.0 12 0 12S0 16 .5 18A3 3 0 002.6 20C4.5 20 12 20 12 20S20 20 21 20A3 3 0 0023 18C24 16 24 12 24 12s0-3.9-.5-5.8zM9.5 16V8.4L16 12 9.5 16z"/></svg></a></div></header><main class=app-container><article class=post><header class=post-header><h1 class=post-title>Osdev: O multithread perdido - Pervasive Multithread</h1><div class=post-meta><div><svg class="icon icon-calendar" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><title>calendar</title><rect x="3" y="4" width="18" height="18" rx="2" ry="2"/><line x1="16" y1="2" x2="16" y2="6"/><line x1="8" y1="2" x2="8" y2="6"/><line x1="3" y1="10" x2="21" y2="10"/></svg>
Nov 28, 2025</div><div><svg class="icon icon-clock" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><title>clock</title><circle cx="12" cy="12" r="10"/><polyline points="12 6 12 12 16 14"/></svg>
5 min read</div><div><svg class="icon icon-tag" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><title>tag</title><path d="M21 13 13 21A2 2 0 0111 21L2 12V2h10L21 11a2 2 0 010 2.8z"/><line x1="7" y1="7" x2="7" y2="7"/></svg>
<a class=tag href=https://foxtechword.github.io/tags/programming/>Programming</a>
<a class=tag href=https://foxtechword.github.io/tags/operating-system/>Operating System</a>
<a class=tag href=https://foxtechword.github.io/tags/osdev/>Osdev</a>
<a class=tag href=https://foxtechword.github.io/tags/c++/>C++</a>
<a class=tag href=https://foxtechword.github.io/tags/haiku/>Haiku</a>
<a class=tag href=https://foxtechword.github.io/tags/beos/>Beos</a></div></div><nav id=TableOfContents><ul><li><ul><li><a href=#o-diferencial-do-beos--haiku>O diferencial do BeOS / Haiku</a></li><li><a href=#o-que-é-pervasive-multithread>O que é Pervasive Multithread</a></li><li><a href=#por-que-smt-não-é-um-cpu--explicação-técnica>Por que SMT não é um “CPU” — explicação técnica</a></li><li><a href=#onde-os-schedulers-modernos-erram>Onde os schedulers modernos erram</a></li><li><a href=#a-proposta-do-fkernel-consciência-de-topologia>A proposta do FKernel: consciência de topologia</a><ul><li><a href=#flag-o_hpc--atalho-para-throughput>Flag <code>O_HPC</code> — atalho para throughput</a></li></ul></li><li><a href=#conclusão>Conclusão</a></li></ul></li></ul></nav></header><div class=post-content><p>Quando olhamos a história dos sistemas operacionais vemos muitas ideias promissoras nascerem, ganharem nichos e, às vezes, sumirem sem deixar rastro. Entre esses projetos, o BeOS — e seu sucessor Haiku — se destacam por uma opção arquitetural clara: priorizar interatividade e baixa latência por meio do que se chamou de Pervasive Multithread.</p><h2 id=o-diferencial-do-beos--haiku>O diferencial do BeOS / Haiku</h2><p>O ponto central é simples: escalonar no nível da thread, com threads muito leves e políticas que favorecem responsividade em vez de throughput máximo. Isso reduz a sobrecarga de contexto ao trocar entre threads da mesma aplicação e permite uma taxa alta de comutação sem penalizar a interatividade.</p><p>Essa ênfase na responsividade ajuda a explicar decisões de projeto aparentemente simples — por exemplo, por que tratar a unidade de escalonamento como a thread em vez do processo — e prepara o terreno para entendermos o conceito que vem a seguir.</p><h2 id=o-que-é-pervasive-multithread>O que é Pervasive Multithread</h2><p>Pervasive Multithread é um modelo composto — kernel e runtime cooperam — em que o sistema trata a concorrência como algo onipresente: o scheduler opera por thread, há prioridades finas (tipicamente 0–120) e políticas que privilegiam latência e previsibilidade sobre o rendimento bruto.</p><p>O resultado prático é que a aplicação vê threads leves com prioridades ajustáveis, e o kernel faz o mínimo necessário ao salvar/restaurar contexto, mantendo a máquina responsiva para cargas interativas.</p><p>Com essa definição em mente, vale contrastar como o hardware moderno tenta aumentar paralelismo com técnicas como SMT — e por que essa camada física pode confundir as decisões de escalonamento quando não é considerada explicitamente.</p><h2 id=por-que-smt-não-é-um-cpu--explicação-técnica>Por que SMT não é um “CPU” — explicação técnica</h2><p>Simultaneous multithreading (SMT) cria múltiplas hardware threads dentro do mesmo núcleo físico. Essas hardware threads compartilham pipelines, unidades funcionais, níveis de cache e o mesmo domínio energético. Em particular:</p><ul><li>Compartilhamento de execution units: duas hardware threads podem disputar as mesmas ALUs, FPU e portas de memória.</li><li>Contenção em caches: L1 e, em muitos designs, partes do L2/L3 são compartilhadas ou têm efeitos de conflito entre threads.</li><li>Dependência de largura de banda e buffers internos: estruturas como reorder buffers e filas de load/store são limitadas por núcleo.</li></ul><p>Esses recursos compartilhados significam que duas hardware threads no mesmo núcleo não oferecem isolamento equivalente ao de dois núcleos físicos. Tratar cada hardware thread como uma CPU independente ignora dependências microarquiteturais e pode degradar throughput e previsibilidade ao induzir contenção e conflitos que o sistema não prevê.</p><p>Em outras palavras: o escalonador que vê apenas &ldquo;CPUs lógicas&rdquo; perde contexto sobre contendas internas do núcleo — um fator crítico quando buscamos baixa latência e previsibilidade.</p><h2 id=onde-os-schedulers-modernos-erram>Onde os schedulers modernos erram</h2><p>Muitos escalonadores expõem cada hardware thread lógico como uma CPU separada (p. ex. quando <code>htop</code> mostra &ldquo;cores lógicos&rdquo;). Essa abstração facilita balanceamento de carga, mas apaga a topologia real: quando cargas pesadas são espalhadas por hardware threads de um mesmo núcleo, surgem colisões internas que reduzem performance por watt e aumentam a variabilidade de latência.</p><p>O problema não é apenas teórico — medições mostram degradações em throughput e latência em cenários de mistura de cargas CPU-bound e latência-sensível quando o escalonador não considera afinidade por núcleo físico e partição de recursos.</p><p>Por isso é importante que camadas de software acima do escalonador compreendam a topologia do processador ou que o próprio escalonador exponha políticas que evitem colocar cargas conflitantes em hardware threads do mesmo núcleo.</p><h2 id=a-proposta-do-fkernel-consciência-de-topologia>A proposta do FKernel: consciência de topologia</h2><p>No FKernel, a responsabilidade de lidar com essa complexidade é deslocada para camadas que entendem o perfil da carga. A ideia central é uma pipeline decidida antes do despacho para hardware threads:</p><p>Green Threads → Multilevel Feedback Queue (MLFQ) → Pervasive Layer → Hardware Threads (SMT)</p><p>Detalhes práticos:</p><ul><li>O MLFQ organiza e amostra comportamento das green threads para estimar sua sensibilidade à latência e ao throughput.</li><li>A Pervasive Layer usa esse perfil para decidir mapeamentos: algumas execuções ocupam uma hardware thread sozinho (para evitar contenda), outras são pareadas com cargas complementares para aproveitar vazios da unidade funcional.</li></ul><p>Isso torna o SMT um recurso gerenciado — um &ldquo;acelerador&rdquo; que é usado conscientemente e não um substituto direto de um núcleo físico.</p><p>Na prática, isso permite duas estratégias opostas: isolar workloads sensíveis à latência em hardware threads próprias, ou cooperar uma workload de alta utilização com outra complementar para maximizar uso de unidades funcionais sem bloquear latência crítica.</p><h3 id=flag-o_hpc--atalho-para-throughput>Flag <code>O_HPC</code> — atalho para throughput</h3><p>Para workloads puramente orientados a throughput, o desenvolvedor pode usar a flag <code>O_HPC</code>. Nesse modo, o caminho é encurtado: a aplicação solicita pinagem e afinidade mais agressivas (possivelmente com garantia de partição de cache L2/L3), sacrificando previsibilidade para ganhar rendimento bruto.</p><p>Em resumo, <code>O_HPC</code> é uma exceção explícita ao modelo orientado a latência — uma forma de o desenvolvedor indicar que prefere rendimento bruto em vez de previsibilidade quando as medições justificam essa escolha.</p><h2 id=conclusão>Conclusão</h2><p>Tratar hardware threads SMT como CPUs independentes é uma simplificação que não reflete a microarquitetura moderna: ela produz contenção interna, variabilidade de latência e desperdício de recursos. O FKernel propõe empurrar a complexidade para camadas que conhecem o perfil das cargas — MLFQ e Pervasive Layer — para mapear threads de forma consciente sobre a topologia real do processador.</p><p>O ganho esperado é simples e direto: menor latência, interatividade consistente e uso mais eficiente de caches e unidades funcionais. Para cargas de throughput extremo, a flag <code>O_HPC</code> permite abrir mão dessa previsibilidade de propósito.</p><p>Se você curte esse tipo de discussão ou quer acompanhar o desenvolvimento do FKernel, deixe um comentário, compartilhe como seu sistema lida com SMT ou sugira workloads para testarmos — medições práticas vão mostrar o impacto real, e eu pretendo publicar resultados em posts futuros.</p><p>Dentre eles temos o <a href=https://en.wikipedia.org/wiki/BeOS>beOS</a> e seu sucessor <a href=https://www.haiku-os.org/>HaikuOS</a>.</p></div><div class=post-footer><div id=disqus_thread></div><script>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("disqus_thread").innerHTML="Disqus comments not available by default when the website is previewed locally.";return}var t=document,e=t.createElement("script");e.async=!0,e.src="//foxtechworld-1.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)}()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></div></article></main></body></html>